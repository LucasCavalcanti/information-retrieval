{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Expansão de Consultas.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasCavalcanti/information-retrieval/blob/master/Expans%C3%A3o_de_Consultas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwyUGjlGd08A",
        "colab_type": "code",
        "outputId": "115dcd5f-cdb4-4168-d304-9927fc2c2aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import RSLPStemmer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')\n",
        "import matplotlib.pyplot as plt\n",
        "import heapq\n",
        "import time\n",
        "import math\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Realizando a leitura do dataset e tokenização\n",
        "\n",
        "db = pd.read_csv(\"https://raw.githubusercontent.com/LucasCavalcanti/ri_lab02/master/results.csv\")\n",
        "\n",
        "documents = db['text']\n",
        "stopwords = stopwords.words(\"portuguese\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMnj2abxsSKO",
        "colab_type": "text"
      },
      "source": [
        "**Questão 1 - Calcule as top-10 palavras mais associadas a cada uma dessas 5 palavras de acordo com as 4 métricas que vimos na aula. Você deve produzir uma tabela similar à tabela 6.3 do capítulo 6 do livro texto (pág. 204). Qual métrica você acha que obteve os melhores resultados? Por que?** \n",
        "\n",
        "As 5 consultas definidas foram:\n",
        "\n",
        "\n",
        "\n",
        "1.  política\n",
        "2.   presidente\n",
        "3.   educação\n",
        "4.   ministério\n",
        "5.   empresa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sywwrfAdsU0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "queries = [\"política\", \"presidente\", \"educação\", \"ministério\", \"empresa\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iT12M4IeAMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildIndex(documents):\n",
        "  toker = RegexpTokenizer(r'\\b[A-zÀ-ú\\d\\-\\']+')\n",
        "  inverted_index = {}\n",
        "  n = 0\n",
        "\n",
        "  for document in documents:\n",
        "    n += 1\n",
        "    tokens = toker.tokenize(document.lower())\n",
        "    for token in set(tokens):\n",
        "      if (token not in stopwords and len(token) >= 2):\n",
        "        value = (n, tokens.count(token))\n",
        "        if (token not in inverted_index.keys()):\n",
        "          inverted_index[token] = []\n",
        "          inverted_index[token].append(value)\n",
        "        else:\n",
        "          inverted_index[token].append(value)\n",
        "  return inverted_index\n",
        "inverted_index = buildIndex(documents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJZQxQUMxKy-",
        "colab_type": "text"
      },
      "source": [
        "**Conta a quantidade de documentos em que a consulta e um token aparecem**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywo0QSX27qYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_nab(index_query, index_item):\n",
        "  nab = 0\n",
        "  for item_a in index_query:\n",
        "    for item_b in index_item:\n",
        "      if (item_a[0] == item_b[0]):\n",
        "        nab += 1\n",
        "  return nab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOcXjzpUxp9s",
        "colab_type": "text"
      },
      "source": [
        "**Cálculo da métrica Mutual Information**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JirX-xaUAEzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mim(na, nb, nab):\n",
        "  divider = (na * nb)\n",
        "  if (divider != 0):\n",
        "    result = nab / divider\n",
        "    return result\n",
        "  else:\n",
        "    return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgW-Bk1QycQ-",
        "colab_type": "text"
      },
      "source": [
        "**Cálculo da métrica Dice's Coefficient**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuhlhpE1_uCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice(na, nb, nab):\n",
        "  divider = (na + nb)\n",
        "  if (divider != 0):\n",
        "    result = nab / divider\n",
        "    return result\n",
        "  else:\n",
        "    return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGX9k8THyik1",
        "colab_type": "text"
      },
      "source": [
        "**Cálculo da métrica Expected Mutual Information**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXiGqvxVCIaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def emim(na, nb, nab, N):\n",
        "  mim = (nab / (na * nb))\n",
        "  if (mim != 0):\n",
        "    result = nab * (math.log(N * mim))\n",
        "    return result\n",
        "  else:\n",
        "    return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JQB5rqwypIm",
        "colab_type": "text"
      },
      "source": [
        "**Cálculo da métrica Chi-Square**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MqVqlZGGukJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chi_square(na, nb, nab, N):\n",
        "  divider = (na * nb)\n",
        "  if (divider != 0):\n",
        "    result = math.pow((nab - ((na*nb)/N)),2)/divider\n",
        "    return result\n",
        "  else:\n",
        "    return 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzZLNhmSyt7v",
        "colab_type": "text"
      },
      "source": [
        "**O método generateMetrics() gera um dicionário onde a chave é consulta e o valor é uma lista com 4 listas, onde cada lista é o top-10 de palavras mais associados a consulta de acordo com cada métrica.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QCCv4G-zzcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateMetrics():\n",
        "  all_metrics = {}\n",
        "\n",
        "  for query in queries:\n",
        "    if (query in inverted_index.keys()):\n",
        "      inverted_list_query = inverted_index[query]\n",
        "      na = len(inverted_list_query)\n",
        "      mim_list = []\n",
        "      dice_list = []\n",
        "      emim_list = []\n",
        "      chi_square_list = []\n",
        "      metrics = []\n",
        "\n",
        "      for item in inverted_index.items():\n",
        "        if (item[0] != query):\n",
        "          inverted_list_item = inverted_index[item[0]]\n",
        "          nb = len(inverted_list_item)\n",
        "          nab = count_nab(inverted_list_query, inverted_list_item)\n",
        "\n",
        "          mim_list.append((item[0], mim (na, nb, nab)))\n",
        "          dice_list.append((item[0], dice (na, nb, nab)))\n",
        "          emim_list.append((item[0], emim (na, nb, nab, len(documents))))\n",
        "          chi_square_list.append((item[0], chi_square (na, nb, nab, len(documents))))\n",
        "\n",
        "\n",
        "\n",
        "      mim_list.sort(key=lambda tup: tup[1])\n",
        "      dice_list.sort(key=lambda tup: tup[1])\n",
        "      emim_list.sort(key=lambda tup: tup[1])\n",
        "      chi_square_list.sort(key=lambda tup: tup[1])\n",
        "      \n",
        "      mim_list.reverse()\n",
        "      dice_list.reverse()\n",
        "      emim_list.reverse()\n",
        "      chi_square_list.reverse()\n",
        "      \n",
        "      metrics.append(mim_list[:10])\n",
        "      metrics.append(dice_list[:10])\n",
        "      metrics.append(emim_list[:10])\n",
        "      metrics.append(chi_square_list[:10])\n",
        "      \n",
        "      all_metrics[query] = metrics\n",
        "\n",
        "\n",
        "  return all_metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-owHx5ZlTEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_metrics = generateMetrics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCP-Gn6rSiN2",
        "colab_type": "text"
      },
      "source": [
        "**O método generateTable() recebe uma consulta como paramêtro e retorna um dataframe com as top-10 palavras mais associadas, de acordo com cada uma das 4 métricas.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TASqE6bMnRjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateTable(query):\n",
        "  mim_metrics = []\n",
        "  dice_metrics = []\n",
        "  emim_metrics = []\n",
        "  chi_square_metrics = []\n",
        "\n",
        "  for item in all_metrics[query][0]:\n",
        "      mim_metrics.append(item[0])\n",
        "  \n",
        "  for item in all_metrics[query][1]:\n",
        "      dice_metrics.append(item[0])\n",
        "  \n",
        "  for item in all_metrics[query][2]:\n",
        "      emim_metrics.append(item[0])\n",
        "  \n",
        "  for item in all_metrics[query][3]:\n",
        "      chi_square_metrics.append(item[0])\n",
        "\n",
        "\n",
        "  metrics_df = pd.DataFrame()\n",
        "  metrics_df['MIM'] = mim_metrics\n",
        "  metrics_df['Dice'] = dice_metrics\n",
        "  metrics_df['EMIM'] = emim_metrics\n",
        "  metrics_df['χ2'] = chi_square_metrics\n",
        "  return metrics_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld2kH0azTFlj",
        "colab_type": "text"
      },
      "source": [
        "**Você deve produzir uma tabela similar à tabela 6.3 do capítulo 6 do livro texto (pág. 204). Qual métrica você acha que obteve os melhores resultados? Por que?**\n",
        "\n",
        "> Para cada consulta gerei a tabela similar a tabela 6.3 do livro texto.\n",
        "\n",
        "\n",
        "> A métrica que obteve os melhores resultados foi a ***chi-quadrado***, pois foi a métrica que retornou as 10 palavras associadas que mais estão relacionadas com a consulta. A métrica EMIM foi a que mais se aproximou da chi-quadrado, e a que obteve pior resultado foi a MIM.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfRMb6JgyX0W",
        "colab_type": "code",
        "outputId": "28801ff9-89ff-404c-fecc-f5a6b5b07b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        }
      },
      "source": [
        "for query in queries:\n",
        "  df = generateTable(query)\n",
        "  print (query)\n",
        "  print (tabulate(df, headers='keys', tablefmt='psql'))\n",
        "  print (\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "política\n",
            "+----+----------------+---------+-----------+--------------+\n",
            "|    | MIM            | Dice    | EMIM      | χ2           |\n",
            "|----+----------------+---------+-----------+--------------|\n",
            "|  0 | governadores   | país    | político  | político     |\n",
            "|  1 | reparamos      | outros  | cada      | desigualdade |\n",
            "|  2 | identitária    | vez     | país      | cientista    |\n",
            "|  3 | vote           | cada    | bolsonaro | eleições     |\n",
            "|  4 | cuide          | governo | governo   | problemas    |\n",
            "|  5 | anula          | pode    | outros    | força        |\n",
            "|  6 | torná-la       | menos   | nacional  | eleição      |\n",
            "|  7 | aprofundado    | contra  | economia  | economia     |\n",
            "|  8 | receptividade  | desde   | problemas | democracia   |\n",
            "|  9 | participativos | parte   | estado    | governos     |\n",
            "+----+----------------+---------+-----------+--------------+\n",
            "\n",
            "presidente\n",
            "+----+-------------------+-----------+-----------+-------------+\n",
            "|    | MIM               | Dice      | EMIM      | χ2          |\n",
            "|----+-------------------+-----------+-----------+-------------|\n",
            "|  0 | centro-americanos | governo   | bolsonaro | bolsonaro   |\n",
            "|  1 | 1999-2013         | bolsonaro | governo   | ministro    |\n",
            "|  2 | chamem-se         | sobre     | ministro  | governo     |\n",
            "|  3 | dirigia           | ainda     | político  | deputado    |\n",
            "|  4 | denominado        | país      | disse     | presidência |\n",
            "|  5 | chegados          | ser       | segurança | secretário  |\n",
            "|  6 | an-124            | disse     | deputado  | militares   |\n",
            "|  7 | antonov           | brasil    | justiça   | twitter     |\n",
            "|  8 | rampa             | ter       | militares | câmara      |\n",
            "|  9 | técnico-militar   | antes     | afirmou   | guedes      |\n",
            "+----+-------------------+-----------+-----------+-------------+\n",
            "\n",
            "educação\n",
            "+----+----------------+-------------+----------+------------+\n",
            "|    | MIM            | Dice        | EMIM     | χ2         |\n",
            "|----+----------------+-------------+----------+------------|\n",
            "|  0 | governadores   | alunos      | social   | aluno      |\n",
            "|  1 | reparamos      | escolas     | alunos   | vélez      |\n",
            "|  2 | identitária    | social      | escolas  | alunos     |\n",
            "|  3 | vote           | mudanças    | escola   | ex-alunos  |\n",
            "|  4 | cuide          | escola      | discurso | mec        |\n",
            "|  5 | anula          | discurso    | governo  | aulas      |\n",
            "|  6 | torná-la       | comissão    | mudanças | aula       |\n",
            "|  7 | aprofundado    | necessidade | comissão | pasta      |\n",
            "|  8 | receptividade  | jovens      | vélez    | escolas    |\n",
            "|  9 | participativos | pasta       | pasta    | estudantes |\n",
            "+----+----------------+-------------+----------+------------+\n",
            "\n",
            "ministério\n",
            "+----+--------------+-----------+-----------+-----------+\n",
            "|    | MIM          | Dice      | EMIM      | χ2        |\n",
            "|----+--------------+-----------+-----------+-----------|\n",
            "|  0 | negociado    | federal   | federal   | pasta     |\n",
            "|  1 | ativadas     | público   | público   | federal   |\n",
            "|  2 | restringidas | ministro  | ministro  | psl       |\n",
            "|  3 | 22h          | militares | militares | feita     |\n",
            "|  4 | continuavam  | valores   | valores   | valores   |\n",
            "|  5 | costeiro     | governo   | feita     | vieira    |\n",
            "|  6 | antimísseis  | disse     | governo   | promovido |\n",
            "|  7 | inutilizados | rio       | disse     | lamenta   |\n",
            "|  8 | enérgica     | justiça   | pasta     | ministro  |\n",
            "|  9 | anoitecer    | pública   | rio       | cidadania |\n",
            "+----+--------------+-----------+-----------+-----------+\n",
            "\n",
            "empresa\n",
            "+----+---------------+----------+------------+------------+\n",
            "|    | MIM           | Dice     | EMIM       | χ2         |\n",
            "|----+---------------+----------+------------+------------|\n",
            "|  0 | transplantes  | reais    | reais      | reais      |\n",
            "|  1 | pestana       | 100      | 100        | 100        |\n",
            "|  2 | ocaso         | empresas | bilhões    | bilhões    |\n",
            "|  3 | condecorações | milhões  | empresas   | bilhão     |\n",
            "|  4 | adversas      | bilhões  | milhões    | acionistas |\n",
            "|  5 | marketing     | dólares  | dólares    | dólares    |\n",
            "|  6 | georgina      | valor    | valor      | fabricação |\n",
            "|  7 | nutrição      | cerca    | cerca      | fabricante |\n",
            "|  8 | dadas         | 000      | bilhão     | empresas   |\n",
            "|  9 | satisfaçam    | além     | acionistas | obteve     |\n",
            "+----+---------------+----------+------------+------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR7QoGqRuPsD",
        "colab_type": "text"
      },
      "source": [
        "**Questão 2 - De acordo com a métrica que deu os melhores resultados na sua opinião, execute agora cada consulta (usando a abordagem documento- ou termo-por-vez)  expandido-a com: os top-3, top-5 e top-10 documentos. O que acontece com a qualidade dos resultados em cada caso? Aumenta ou diminui? Justifique bem sua resposta.** \n",
        "\n",
        "> Nessa questão utilizei a abordagem documento-por-vez e expandi as consultas com as palavras resultantes da métrica chi-quadrado que foi a que obteve os melhores resultados.\n",
        "\n",
        "\n",
        "> A medida que aumentamos o número de palavras na expansão da consulta a qualidade dos resultados aumenta, pois o score de documentos que contêm além da palavra da consulta, as novas palavras associadas, aumenta e com isso entram no top-10, retornando assim resultados relevantes para a consulta, que não estavam sendo retornados antes da expansão da consulta.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjlICpQGeX-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def documentAtATime(query, inverted_index, k):\n",
        "  inverted_lists = []\n",
        "  r = []\n",
        "  for word in query.split(\" \"):\n",
        "    if word in inverted_index.keys():\n",
        "      inverted_lists.append(inverted_index[word])\n",
        "  for document in range(1, len(documents)+1):\n",
        "    sd = 0\n",
        "    for inverted_list in inverted_lists:\n",
        "      for post in inverted_list:\n",
        "        if (post[0] == document):\n",
        "          sd += post[1]\n",
        "          break\n",
        "    if (sd != 0):\n",
        "      heapq.heappush(r, (sd, document))\n",
        "  return heapq.nlargest(k, r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACcU95TnUmmN",
        "colab_type": "text"
      },
      "source": [
        "**Método para expandir a consulta, onde k é número de palavras que desejo expandir, que no nosso caso será 3, 5 ou 10 e retorna a consulta expandida com as top-k palavras mais associadas, utilizando o resultado da métrica chi-square.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff2XP_779xOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def queryExpansion(query, k):\n",
        "  consulta = query\n",
        "  top_words = generateTable(query).χ2[:k]\n",
        "  \n",
        "  for word in top_words:\n",
        "    consulta += \" \" + word\n",
        "  return consulta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvQ8bNntV-0y",
        "colab_type": "text"
      },
      "source": [
        "**Método que recebe uma consulta e realiza sua expansão com os top-3, top-5 e top-10 palavras mais associadas, faz a consulta utilizando a abordagem documento-por-vez e retorna um dataframe com os resultados dos documentos mais relevantes para cada consulta expandida.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4DMrQA55dwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateQueryExpansionTable(query):\n",
        "\n",
        "  results_top_3 = []\n",
        "  results_top_5 = []\n",
        "  results_top_10 = []\n",
        "\n",
        "  query_expansion = queryExpansion(query, 3)\n",
        "  query_expansion_documents = documentAtATime(query_expansion, inverted_index, 10)\n",
        "  for item in query_expansion_documents:\n",
        "    results_top_3.append(item[1])\n",
        "\n",
        "  query_expansion = queryExpansion(query, 5)\n",
        "  query_expansion_documents = documentAtATime(query_expansion, inverted_index, 10)\n",
        "  for item in query_expansion_documents:\n",
        "    results_top_5.append(item[1])\n",
        "\n",
        "  query_expansion = queryExpansion(query, 10)\n",
        "  query_expansion_documents = documentAtATime(query_expansion, inverted_index, 10)\n",
        "  for item in query_expansion_documents:\n",
        "    results_top_10.append(item[1])\n",
        "\n",
        "  query_expansion_df = pd.DataFrame()\n",
        "  query_expansion_df['query_expansion_top3'] = results_top_3\n",
        "  query_expansion_df['query_expansion_top5'] = results_top_5\n",
        "  query_expansion_df['query_expansion_top10'] = results_top_10\n",
        "  return query_expansion_df\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnEH4rvokTNp",
        "colab_type": "text"
      },
      "source": [
        "**Gero o dataframe com os resultados do top-10 documentos mais relevantes para cada consulta expandida.**\n",
        "\n",
        "> **query_expansion_top3** = Consulta expandida com as 3 palavras mais associadas.\n",
        "\n",
        "> **query_expansion_top5** = Consulta expandida com as 5 palavras mais associadas.\n",
        "\n",
        "> **query_expansion_top10** = Consulta expandida com as 10 palavras mais associadas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUNS8dWS68nm",
        "colab_type": "code",
        "outputId": "5939c326-947f-45fc-c705-2f55cfd6b8e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        }
      },
      "source": [
        "for query in queries:\n",
        "  print (query)\n",
        "  print (tabulate(generateQueryExpansionTable(query), headers='keys', tablefmt='psql'))\n",
        "  print (\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "política\n",
            "+----+------------------------+------------------------+-------------------------+\n",
            "|    |   query_expansion_top3 |   query_expansion_top5 |   query_expansion_top10 |\n",
            "|----+------------------------+------------------------+-------------------------|\n",
            "|  0 |                     69 |                     69 |                      69 |\n",
            "|  1 |                    165 |                     86 |                     248 |\n",
            "|  2 |                     86 |                    152 |                     166 |\n",
            "|  3 |                    168 |                    211 |                     165 |\n",
            "|  4 |                    166 |                    165 |                      86 |\n",
            "|  5 |                     63 |                     63 |                     210 |\n",
            "|  6 |                      7 |                    173 |                     138 |\n",
            "|  7 |                    204 |                    168 |                     211 |\n",
            "|  8 |                    173 |                    166 |                     173 |\n",
            "|  9 |                    152 |                     84 |                     152 |\n",
            "+----+------------------------+------------------------+-------------------------+\n",
            "\n",
            "presidente\n",
            "+----+------------------------+------------------------+-------------------------+\n",
            "|    |   query_expansion_top3 |   query_expansion_top5 |   query_expansion_top10 |\n",
            "|----+------------------------+------------------------+-------------------------|\n",
            "|  0 |                    166 |                    166 |                     166 |\n",
            "|  1 |                    151 |                    151 |                     151 |\n",
            "|  2 |                     19 |                     19 |                     207 |\n",
            "|  3 |                    207 |                    207 |                      19 |\n",
            "|  4 |                    225 |                    205 |                     209 |\n",
            "|  5 |                    205 |                     63 |                     205 |\n",
            "|  6 |                     63 |                    235 |                     240 |\n",
            "|  7 |                    235 |                    225 |                     208 |\n",
            "|  8 |                    208 |                    240 |                      63 |\n",
            "|  9 |                    115 |                    208 |                     225 |\n",
            "+----+------------------------+------------------------+-------------------------+\n",
            "\n",
            "educação\n",
            "+----+------------------------+------------------------+-------------------------+\n",
            "|    |   query_expansion_top3 |   query_expansion_top5 |   query_expansion_top10 |\n",
            "|----+------------------------+------------------------+-------------------------|\n",
            "|  0 |                    221 |                    221 |                     239 |\n",
            "|  1 |                    130 |                    130 |                     221 |\n",
            "|  2 |                    239 |                    239 |                     130 |\n",
            "|  3 |                    222 |                    222 |                     110 |\n",
            "|  4 |                    110 |                    110 |                     222 |\n",
            "|  5 |                    214 |                    215 |                     214 |\n",
            "|  6 |                    215 |                    214 |                     216 |\n",
            "|  7 |                    160 |                    233 |                     215 |\n",
            "|  8 |                    233 |                    160 |                     115 |\n",
            "|  9 |                     37 |                     37 |                     160 |\n",
            "+----+------------------------+------------------------+-------------------------+\n",
            "\n",
            "ministério\n",
            "+----+------------------------+------------------------+-------------------------+\n",
            "|    |   query_expansion_top3 |   query_expansion_top5 |   query_expansion_top10 |\n",
            "|----+------------------------+------------------------+-------------------------|\n",
            "|  0 |                    115 |                    115 |                     115 |\n",
            "|  1 |                    221 |                    207 |                     207 |\n",
            "|  2 |                    151 |                    221 |                     151 |\n",
            "|  3 |                    203 |                    220 |                     221 |\n",
            "|  4 |                    220 |                    203 |                     209 |\n",
            "|  5 |                    124 |                    151 |                     222 |\n",
            "|  6 |                    225 |                    124 |                     220 |\n",
            "|  7 |                    213 |                    213 |                     213 |\n",
            "|  8 |                    205 |                    173 |                     203 |\n",
            "|  9 |                    233 |                    225 |                     240 |\n",
            "+----+------------------------+------------------------+-------------------------+\n",
            "\n",
            "empresa\n",
            "+----+------------------------+------------------------+-------------------------+\n",
            "|    |   query_expansion_top3 |   query_expansion_top5 |   query_expansion_top10 |\n",
            "|----+------------------------+------------------------+-------------------------|\n",
            "|  0 |                    142 |                    142 |                     142 |\n",
            "|  1 |                    207 |                    207 |                     143 |\n",
            "|  2 |                    136 |                    143 |                     135 |\n",
            "|  3 |                    143 |                    136 |                      22 |\n",
            "|  4 |                    135 |                    135 |                     207 |\n",
            "|  5 |                     40 |                     22 |                     136 |\n",
            "|  6 |                     22 |                    220 |                     145 |\n",
            "|  7 |                    243 |                    139 |                      40 |\n",
            "|  8 |                    145 |                     40 |                     220 |\n",
            "|  9 |                    139 |                    243 |                     243 |\n",
            "+----+------------------------+------------------------+-------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}